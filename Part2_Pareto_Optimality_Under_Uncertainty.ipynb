{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "984af293",
   "metadata": {},
   "source": [
    "# Pareto Optimality Under Uncertainty\n",
    "\n",
    "Now that we know what Pareto optimality is and that there's a tool to efficiently perform MOO, we have to face another problem: such undertaking is computationally expensive -- for large-scale real-world numerical model, one such forward run could take hours, let alone hundreds of thousand of runs required in MOO.\n",
    "\n",
    "For this tutorial, we will demonstrate how we can speed up the process of MOO by using a surrogate model, without compromising the reliability of solutions. We will still be using the 2D modified Kursawe problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bef47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyemu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085dd863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kursawe_2d(x):\n",
    "    x = np.array(x)\n",
    "    obj1 = -10 * np.exp(-0.2 * np.sqrt(x[0]**2 + x[1]**2))\n",
    "    obj2 = np.abs(x[0])**0.8 + 5 * np.sin(x[0]**3) + np.abs(x[1])**0.8 + 5 * np.sin(x[1]**3)\n",
    "    return obj1, obj2\n",
    "\n",
    "n_samples = 100\n",
    "x1_range = np.linspace(-5, 5, int(np.sqrt(n_samples)))\n",
    "x2_range = np.linspace(-5, 5, int(np.sqrt(n_samples)))\n",
    "x1, x2 = np.meshgrid(x1_range, x2_range)\n",
    "x1 = x1.flatten()\n",
    "x2 = x2.flatten()\n",
    "\n",
    "x1 = x1[:n_samples]\n",
    "x2 = x2[:n_samples]\n",
    "\n",
    "n_actual = min(len(x1), len(x2))\n",
    "objectives = np.array([kursawe_2d([x1[i], x2[i]]) for i in range(n_actual)])\n",
    "obj1 = objectives[:, 0]\n",
    "obj2 = objectives[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ddb3b2",
   "metadata": {},
   "source": [
    "Let us first generate the template files we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed69c779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kursawe2d_demo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_d = \"./demo_files/kursawe2d\"\n",
    "assert os.path.exists(base_d)\n",
    "\n",
    "temp_d = \"kursawe2d_demo\"\n",
    "if os.path.exists(temp_d):\n",
    "    shutil.rmtree(temp_d)\n",
    "shutil.copytree(base_d,temp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0e506f",
   "metadata": {},
   "source": [
    "We can easily find Pareto optimal set of decision variables by running PESTPP-MOU. Let's generate an initial swarm size of 30 and perform 20 iterations of MOO. To ensure that our initial population is evenly distributed and sufficiently samples the decision space, it is advisable to use Latin Hypercube Sampling (LHS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd4391b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noptmax:20, npar_adj:2, nnz_obs:2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gen=0_member=0</th>\n",
       "      <td>-2.900058</td>\n",
       "      <td>2.001396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen=0_member=1</th>\n",
       "      <td>-1.283856</td>\n",
       "      <td>2.516370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen=0_member=2</th>\n",
       "      <td>2.938901</td>\n",
       "      <td>3.057931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen=0_member=3</th>\n",
       "      <td>0.581404</td>\n",
       "      <td>-0.445164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen=0_member=4</th>\n",
       "      <td>3.307439</td>\n",
       "      <td>-4.730684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      x1        x2\n",
       "real_name                         \n",
       "gen=0_member=0 -2.900058  2.001396\n",
       "gen=0_member=1 -1.283856  2.516370\n",
       "gen=0_member=2  2.938901  3.057931\n",
       "gen=0_member=3  0.581404 -0.445164\n",
       "gen=0_member=4  3.307439 -4.730684"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can change the size of initial sample or the number of inner iterations if you want to try other values. \n",
    "# Just be aware that larger sample size and more inner iterations will take longer time to run.\n",
    "swarm_size = 20\n",
    "nmax_inner = 20\n",
    "\n",
    "sys.path.append('./bin')\n",
    "from LHS_sampler import generate_lhsstarter\n",
    "bounds = np.array([[-5, 5] for i in range(2)])\n",
    "generate_lhsstarter(os.path.join(temp_d,'kursawe2d_pbm_template'), seed=42, n_samples=swarm_size, n_dimensions=2, bounds=bounds) \n",
    "\n",
    "pst_file = os.path.join(temp_d, 'kursawe2d_pbm_template', 'kur.pst')\n",
    "pst = pyemu.Pst(pst_file)\n",
    "pst.pestpp_options['mou_population_size'] = swarm_size\n",
    "pst.pestpp_options['mou_dv_population_file'] = 'starter.dv_pop.csv'\n",
    "pst.control_data.noptmax = nmax_inner\n",
    "pst.write(os.path.join(temp_d, 'kursawe2d_pbm_template', os.path.basename(pst_file)))\n",
    "\n",
    "starter_pop = pd.read_csv(os.path.join(temp_d, \"kursawe2d_pbm_template\", \"starter.dv_pop.csv\"), index_col=\"real_name\")\n",
    "starter_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b314295",
   "metadata": {},
   "source": [
    "Now that we have generated an initial population, let us run pestpp-mou..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d52eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "tmpl_in = os.path.join(temp_d, \"kursawe2d_pbm_template\")\n",
    "sys.path.insert(0,tmpl_in)\n",
    "from forward_pbrun import ppw_worker as ppw_function\n",
    "pyemu.os_utils.start_workers(tmpl_in, \"../../bin/pestpp-mou\", \"kur.pst\", num_workers = num_workers,\n",
    "                             worker_root = temp_d, master_dir = os.path.join(temp_d, \"pbm_run\"),\n",
    "                             ppw_function = ppw_function)\n",
    "sys.path.remove(tmpl_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e47a7",
   "metadata": {},
   "source": [
    "Let's plot the resulting Pareto front. Use the slider to observe how the swarm's position evolves in the objective space at each iteration as it searches for the Pareto front until it eventually converge. Also observe how the swarm moves in the decision space.\n",
    "\n",
    "We will revisit this later to compare with SAMOO, which will be introduced in Part 3 of this tutorial. This will be referred to as \"Complex MOO\" run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59fa5814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220a284e937d4079ad8796322011badf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=20, continuous_update=False, description='Generation:', max=20), HBox(children=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider, HBox, VBox, Output\n",
    "from IPython.display import display\n",
    "from scipy.interpolate import griddata\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "run_data = pd.read_csv(os.path.join(temp_d, \"pbm_run\", \"kur.pareto.summary.csv\"))\n",
    "max_gen = max(run_data['generation'])\n",
    "\n",
    "csvfiles = sorted(glob.glob(os.path.join(temp_d, \"pbm_run\", \"*[0-999].dv_pop.csv\"), recursive=True), \n",
    "                  key=lambda x: int(x.split(\".dv\")[0].split(\".\")[1]))\n",
    "all_dv_list = []\n",
    "for file in csvfiles:\n",
    "    generation = int(file.split(\".dv\")[0].split(\".\")[1])\n",
    "    df = pd.read_csv(file).assign(generation=generation)\n",
    "    df = df[['generation'] + [col for col in df.columns if col != 'generation']] \n",
    "    all_dv_list.append(df)\n",
    "all_dv = pd.concat(all_dv_list, ignore_index=True)\n",
    "\n",
    "csvfiles = sorted(glob.glob(os.path.join(temp_d, \"pbm_run\", \"*[0-999].obs_pop.csv\"), recursive=True), \n",
    "                      key=lambda x: int(x.split(\".obs\")[0].split(\".\")[1]))\n",
    "\n",
    "all_obs_list = []\n",
    "for file in csvfiles:\n",
    "    generation = int(file.split(\".obs\")[0].split(\".\")[1])\n",
    "    df = pd.read_csv(file).assign(generation=generation)\n",
    "    df = df[['generation'] + [col for col in df.columns if col != 'generation']] \n",
    "    all_obs_list.append(df)\n",
    "all_obs = pd.concat(all_obs_list, ignore_index=True)\n",
    "\n",
    "all_data = pd.merge(all_dv, all_obs, on=['generation', 'real_name'])\n",
    "max_gen = max(all_data['generation'])\n",
    "\n",
    "n_samples = 100\n",
    "x1_range = np.linspace(-5, 5, int(np.sqrt(n_samples)))\n",
    "x2_range = np.linspace(-5, 5, int(np.sqrt(n_samples)))\n",
    "x1, x2 = np.meshgrid(x1_range, x2_range)\n",
    "x1 = x1.flatten()\n",
    "x2 = x2.flatten()\n",
    "\n",
    "x1 = x1[:n_samples]\n",
    "x2 = x2[:n_samples]\n",
    "\n",
    "n_actual = min(len(x1), len(x2))\n",
    "objectives = np.array([kursawe_2d([x1[i], x2[i]]) for i in range(n_actual)])\n",
    "obj1 = objectives[:, 0]\n",
    "obj2 = objectives[:, 1]\n",
    "\n",
    "xi = np.linspace(min(x1), max(x1), n_samples)\n",
    "yi = np.linspace(min(x2), max(x2), n_samples)\n",
    "xi_grid, yi_grid = np.meshgrid(xi, yi)\n",
    "zi1 = griddata((x1, x2), obj1, (xi_grid, yi_grid), method='cubic')\n",
    "zi2 = griddata((x1, x2), obj2, (xi_grid, yi_grid), method='cubic')\n",
    "\n",
    "out_pareto = Output()\n",
    "out_obj_space = Output()\n",
    "out_contour = Output()\n",
    "\n",
    "true_pareto = pd.read_csv(os.path.join('kursawe2d_demo', 'kursawe2d_solution_obj.csv'))\n",
    "\n",
    "def moo_plot_all(generation):\n",
    "    with out_pareto:\n",
    "        out_pareto.clear_output(wait=True)\n",
    "        pareto = run_data.loc[(run_data['generation']==generation) & (run_data['nsga2_front'] == 1)]\n",
    "        plt.figure(figsize=(5, 6))\n",
    "        plt.scatter(pareto['obj1'], pareto['obj2'], c='firebrick', s=30, alpha=0.7, label = 'current non-dominated positions')\n",
    "        plt.scatter(true_pareto['obj1'], true_pareto['obj2'], c='deepskyblue', s=20, zorder = -10, label='Pareto optimal solutions')\n",
    "        plt.xlabel('Objective 1')\n",
    "        plt.ylabel('Objective 2')\n",
    "        plt.xlim((-10.5, -2))\n",
    "        plt.ylim((-10, 15))\n",
    "        plt.legend()\n",
    "        plt.title(f'Pareto Front at Generation {generation}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    with out_obj_space:\n",
    "        out_obj_space.clear_output(wait=True)\n",
    "        all_points = run_data.loc[(run_data['generation']==generation)]\n",
    "        plt.figure(figsize=(5, 6))\n",
    "        plt.scatter(all_points['obj1'], all_points['obj2'], edgecolor='green', c = 'none', s=30, alpha=0.7, label = 'all candidate positions')\n",
    "        plt.scatter(true_pareto['obj1'], true_pareto['obj2'], c='deepskyblue', s=20, zorder = -10, label='Pareto optimal solutions')\n",
    "        plt.xlabel('Objective 1')\n",
    "        plt.ylabel('Objective 2')\n",
    "        plt.xlim((-10.5, -2))\n",
    "        plt.ylim((-10, 15))\n",
    "        plt.legend()\n",
    "        plt.title(f'Objective Space at Generation {generation}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # with out_contour:\n",
    "    #     out_contour.clear_output(wait=True)\n",
    "    #     fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    #     contour1 = ax.contourf(xi_grid, yi_grid, zi2, 15, cmap='plasma', alpha=0.5)\n",
    "    #     fig.colorbar(contour1, ax=ax, label='Objective 1')\n",
    "    #     contour2 = ax.contour(xi_grid, yi_grid, zi1, 15, cmap='viridis', alpha=0.7)\n",
    "    #     fig.colorbar(contour2, ax=ax, label='Objective 2')\n",
    "\n",
    "    #     pareto = run_data.loc[(run_data['generation']==generation) & (run_data['nsga2_front'] == 1)]\n",
    "    #     pareto_members = pareto['member'].values\n",
    "    #     pareto_dv = all_data[all_data['real_name'].isin(pareto_members)]\n",
    "    #     ax.scatter(pareto_dv['x1'], pareto_dv['x2'], edgecolor='firebrick', facecolor='none', s=40, alpha=0.8)\n",
    "        \n",
    "    #     ax.set_xlabel('x1')\n",
    "    #     ax.set_ylabel('x2')\n",
    "    #     ax.set_title(f'Pareto Optimal Decisions at Generation {generation}')\n",
    "    #     ax.grid(True)\n",
    "    #     plt.tight_layout()\n",
    "    #     plt.show()\n",
    "\n",
    "generation_slider = IntSlider(min=0, max=max_gen, step=1, value=max_gen, \n",
    "                             description='Generation:',\n",
    "                             continuous_update=False)\n",
    "moo_plot_all(max_gen)\n",
    "\n",
    "generation_slider.observe(lambda change: moo_plot_all(change['new']), names='value')\n",
    "display(VBox([\n",
    "    generation_slider,\n",
    "    HBox([out_obj_space, out_pareto]),\n",
    "    out_contour\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0b33fd",
   "metadata": {},
   "source": [
    "As this benchmark is not too complex, it doesn't take much time to complete one iteration and it doesn't take a lot of iteration to obtain a set of Pareto optimal solutions. However, in reality, real-world models do not run this fast. Even with parallelisation, it can take a few hundred, even thousand iterations until the swarm converges to the Pareto front. If important timely decisions rely on the outcome of such optimisation process, we would need some help to speed up this process. \n",
    "\n",
    "Let's pretend for a while that the Fonseca-Fleming problem is a complex model that is expensive to evaluate. There's nothing we could do about the run time of the complex model. What we can do though is to employ an \"emulator\", a faster and cheaper model that approximates the relationships between the known (i.e., previously evaluated) input and outputs of the complex model in order to predict its response to some input values that were not previously evaluated. This emulator is also known as the surrogate model. Because the surrogate model is an approximation, its prediction has errors. These errors could mislead the decision-making to some suboptimal solutions that are not actually in the Pareto front. This is some price to pay for speeding up the process, but don't worry as we have means to manage these uncertainties and still obtain truly Pareto optimal solutions.\n",
    "\n",
    "There are many surrogate models available in literature. However, we will use Gaussian Process Regression (GPR) as it provides a convenient way to take into account the uncertainty in predictions of the surrogate model, which, as previously said, needs to be managed well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e746fe95",
   "metadata": {},
   "source": [
    "Let's take a quick detour to see how GPR works. Here's a nonlinear function with 1D input and output. We generate 10 training points composed of the inputs and corresponding outputs when evaluated in the nonlinear function. We then use the training points to predict the output of the nonlinear function at some test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be926d18",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "cannot do a non-empty take from an empty axes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# True function: f(x) = sin(x) + 0.1*x^2\u001b[39;00m\n\u001b[0;32m     10\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msin(X_train) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msquare(X_train) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 12\u001b[0m gp \u001b[38;5;241m=\u001b[39m gpr\u001b[38;5;241m.\u001b[39mbuildGP(X_train, y_train, wdir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./kursawe2d_demo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Create test points for prediction\u001b[39;00m\n\u001b[0;32m     15\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m20\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[1;32mc:\\Users\\mac732\\AppData\\Local\\anaconda3\\Lib\\site-packages\\laGPy\\gp.py:846\u001b[0m, in \u001b[0;36mbuildGP\u001b[1;34m(X, Z, d, g, wdir, fname, export, verb)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuildGP\u001b[39m(X: np\u001b[38;5;241m.\u001b[39mndarray, \n\u001b[0;32m    815\u001b[0m          Z: np\u001b[38;5;241m.\u001b[39mndarray, \n\u001b[0;32m    816\u001b[0m          d: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m          export: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    821\u001b[0m          verb: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GP:\n\u001b[0;32m    822\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;124;03m    Builds GP for Gaussian Process Regression. \u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;124;03m    Uses all the training data to build the model (i.e., not a local approximate GP!).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;124;03m            X: Design matrix\u001b[39;00m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 846\u001b[0m     d_prior \u001b[38;5;241m=\u001b[39m darg(d, X)\n\u001b[0;32m    847\u001b[0m     g_prior \u001b[38;5;241m=\u001b[39m garg(g, Z)\n\u001b[0;32m    849\u001b[0m     gp \u001b[38;5;241m=\u001b[39m newGP(X, Z, get_value(d_prior, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m), get_value(g_prior, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\mac732\\AppData\\Local\\anaconda3\\Lib\\site-packages\\laGPy\\params.py:179\u001b[0m, in \u001b[0;36mdarg\u001b[1;34m(d, X, samp_size)\u001b[0m\n\u001b[0;32m    166\u001b[0m need_Ds \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m d \u001b[38;5;129;01mor\u001b[39;00m \n\u001b[0;32m    168\u001b[0m     (d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m     ))\n\u001b[0;32m    176\u001b[0m )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_Ds:\n\u001b[1;32m--> 179\u001b[0m     Ds \u001b[38;5;241m=\u001b[39m get_Ds(X, samp_size\u001b[38;5;241m=\u001b[39msamp_size)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# Check for starting value\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m d:\n",
      "File \u001b[1;32mc:\\Users\\mac732\\AppData\\Local\\anaconda3\\Lib\\site-packages\\laGPy\\params.py:54\u001b[0m, in \u001b[0;36mget_Ds\u001b[1;34m(X, p, samp_size)\u001b[0m\n\u001b[0;32m     50\u001b[0m D \u001b[38;5;241m=\u001b[39m D[np\u001b[38;5;241m.\u001b[39mtriu_indices_from(D, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m     51\u001b[0m D \u001b[38;5;241m=\u001b[39m D[D \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mquantile(D, p),\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmin(D),\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmax(D)\n\u001b[0;32m     57\u001b[0m }\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mquantile\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mac732\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4461\u001b[0m, in \u001b[0;36mquantile\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[0;32m   4459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[0;32m   4460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantiles must be in the range [0, 1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 4461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _quantile_unchecked(\n\u001b[0;32m   4462\u001b[0m     a, q, axis, out, overwrite_input, method, keepdims)\n",
      "File \u001b[1;32mc:\\Users\\mac732\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4473\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[0;32m   4465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[0;32m   4466\u001b[0m                         q,\n\u001b[0;32m   4467\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4470\u001b[0m                         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4471\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   4472\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ureduce(a,\n\u001b[0;32m   4474\u001b[0m                     func\u001b[38;5;241m=\u001b[39m_quantile_ureduce_func,\n\u001b[0;32m   4475\u001b[0m                     q\u001b[38;5;241m=\u001b[39mq,\n\u001b[0;32m   4476\u001b[0m                     keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[0;32m   4477\u001b[0m                     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   4478\u001b[0m                     out\u001b[38;5;241m=\u001b[39mout,\n\u001b[0;32m   4479\u001b[0m                     overwrite_input\u001b[38;5;241m=\u001b[39moverwrite_input,\n\u001b[0;32m   4480\u001b[0m                     method\u001b[38;5;241m=\u001b[39mmethod)\n",
      "File \u001b[1;32mc:\\Users\\mac732\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:3752\u001b[0m, in \u001b[0;36m_ureduce\u001b[1;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[0;32m   3749\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[0;32m   3750\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[1;32m-> 3752\u001b[0m r \u001b[38;5;241m=\u001b[39m func(a, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\mac732\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4639\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[0;32m   4637\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4638\u001b[0m         arr \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m-> 4639\u001b[0m result \u001b[38;5;241m=\u001b[39m _quantile(arr,\n\u001b[0;32m   4640\u001b[0m                    quantiles\u001b[38;5;241m=\u001b[39mq,\n\u001b[0;32m   4641\u001b[0m                    axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   4642\u001b[0m                    method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   4643\u001b[0m                    out\u001b[38;5;241m=\u001b[39mout)\n\u001b[0;32m   4644\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\mac732\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4745\u001b[0m, in \u001b[0;36m_quantile\u001b[1;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[0;32m   4737\u001b[0m arr\u001b[38;5;241m.\u001b[39mpartition(\n\u001b[0;32m   4738\u001b[0m     np\u001b[38;5;241m.\u001b[39munique(np\u001b[38;5;241m.\u001b[39mconcatenate(([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   4739\u001b[0m                               previous_indexes\u001b[38;5;241m.\u001b[39mravel(),\n\u001b[0;32m   4740\u001b[0m                               next_indexes\u001b[38;5;241m.\u001b[39mravel(),\n\u001b[0;32m   4741\u001b[0m                               ))),\n\u001b[0;32m   4742\u001b[0m     axis\u001b[38;5;241m=\u001b[39mDATA_AXIS)\n\u001b[0;32m   4743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minexact):\n\u001b[0;32m   4744\u001b[0m     slices_having_nans \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(\n\u001b[1;32m-> 4745\u001b[0m         take(arr, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39mDATA_AXIS)\n\u001b[0;32m   4746\u001b[0m     )\n\u001b[0;32m   4747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4748\u001b[0m     slices_having_nans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mtake\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mac732\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:190\u001b[0m, in \u001b[0;36mtake\u001b[1;34m(a, indices, axis, out, mode)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_take_dispatcher)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtake\u001b[39m(a, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Take elements from an array along an axis.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m           [5, 7]])\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m'\u001b[39m, indices, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[1;32mc:\\Users\\mac732\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mIndexError\u001b[0m: cannot do a non-empty take from an empty axes."
     ]
    }
   ],
   "source": [
    "import laGPy as gpr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "\n",
    "# Generate some training data with a non-linear function\n",
    "np.random.seed(42)\n",
    "X_train = np.sort(np.random.uniform(-3, 3, 10))\n",
    "# True function: f(x) = sin(x) + 0.1*x^2\n",
    "y_train = np.sin(X_train) + 0.1 * np.square(X_train) + np.random.normal(0, 0.1, X_train.shape)\n",
    "\n",
    "gp = gpr.buildGP(X_train, y_train, wdir = './kursawe2d_demo')\n",
    "\n",
    "# Create test points for prediction\n",
    "X_test = np.linspace(-4, 4, 20)[:, np.newaxis]\n",
    "\n",
    "# Process each row in X_test individually and store results in arrays\n",
    "loaded_gp = gp.loadGP()\n",
    "mean_pred = np.zeros(X_test.shape[0])\n",
    "std_pred = np.zeros(X_test.shape[0])\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_row = X_test[i:i+1]  # Get single row as 2D array\n",
    "    sims = loaded_gp.predict_lite(X_row)\n",
    "    mean_pred[i] = sims['mean']\n",
    "    std_pred[i] = np.sqrt(sims['s2'])\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training points\n",
    "plt.scatter(X_train, y_train, color='red', label='Training points', s=50, zorder=3)\n",
    "\n",
    "# Plot the mean prediction\n",
    "plt.plot(X_test, mean_pred, color='blue', label='Mean prediction')\n",
    "\n",
    "# Plot the confidence interval (Â±2 standard deviations, 95% confidence)\n",
    "plt.fill_between(X_test.ravel(), \n",
    "                 mean_pred - 2 * std_pred, \n",
    "                 mean_pred + 2 * std_pred, \n",
    "                 color='blue', alpha=0.2, label='95% confidence interval')\n",
    "\n",
    "# Plot the true function for comparison\n",
    "true_y = np.sin(X_test) + 0.1 * np.square(X_test)\n",
    "plt.plot(X_test, true_y, color='green', linestyle='--', label='True function')\n",
    "\n",
    "plt.title('Gaussian Process Regression Example')\n",
    "plt.xlabel('Input (x)')\n",
    "plt.ylabel('Output (y)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the learned kernel parameters\n",
    "print(\"Learned kernel parameters:\")\n",
    "print(f\"Length scale: {gp.kernel_.length_scale}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52abf7d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
